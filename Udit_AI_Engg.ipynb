{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPN57nMRS/fMKYlZXKoD10a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uditsingh7/AI-Collab/blob/main/Udit_AI_Engg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U flash-attn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "id2lh3leU7SU",
        "outputId": "7d174811-7781-44f7-ebaf-90674f96b37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/6.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.6.0+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->flash-attn)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->flash-attn)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->flash-attn)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->flash-attn)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->flash-attn)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->flash-attn)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->flash-attn)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m123.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flash-attn\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed flash-attn-2.7.4.post1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QppJqhU0PLh-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "4b7ffac5-c8d3-4847-8dcb-3af4facfd859"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'flash_attn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e5edf40f3a88>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mflash_attn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flash_attn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import flash_attn\n",
        "import time\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/DeepHermes-3-Llama-3-3B-Preview\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"NousResearch/DeepHermes-3-Llama-3-3B-Preview\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    attn_implementation=\"flash_attention_2\",\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is y if y=2*2-4+(3*2)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "print(f\"Generated Tokens: {generated_ids.shape[-1:]}\")\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")"
      ],
      "metadata": {
        "id": "8BHP9wxQbP46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## System not mandatory, bt behaves like instrction or hwo model shold behave\n",
        "## user is mandatory, it gives the AI something to respond to.\n",
        "messages = [\n",
        "    # {\n",
        "    #     \"role\": \"system\",\n",
        "    #     \"content\": \"You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem.\"\n",
        "    # },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is y if y=2*2-4+(3*2)\"\n",
        "    }\n",
        "]\n",
        "\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "print(f\"Generated Tokens: {generated_ids.shape[-1:]}\")\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu2OSppJeMKL",
        "outputId": "ecc2c20e-3d3e-46ba-e62b-35cdc5445eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Tokens: torch.Size([80])\n",
            "Response: user\n",
            "\n",
            "What is y if y=2*2-4+(3*2)assistant\n",
            "\n",
            "The expression can be evaluated as follows:\n",
            "```\n",
            "y = 2 * 2 - 4 + (3 * 2)\n",
            "   = 4 - 4 + 6\n",
            "   = 10\n",
            "```So the value of y is 10.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COT example\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an AI that breaks down problems into clear steps and thinks deeply before answering. Use <think></think> to enclose your reasoning process.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"If a car travels 60 kilometers in 1 hour, how far will it travel in 5 hours?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=500, temperature=0.8, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Displaying the generated response\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waZE_9PSe6Os",
        "outputId": "1ad3b822-ba29-4f37-bce4-6cf2c6e5c5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "You are an AI that breaks down problems into clear steps and thinks deeply before answering. Use <think></think> to enclose your reasoning process.user\n",
            "\n",
            "If a car travels 60 kilometers in 1 hour, how far will it travel in 5 hours?assistant\n",
            "\n",
            "<think>\n",
            "Okay, so the question is: If a car travels 60 kilometers in 1 hour, how far will it travel in 5 hours?\n",
            "\n",
            "First, let me make sure I understand what's being asked here. The car goes 60 km in one hour. We need to find out how much distance it will cover in five hours instead of just one.\n",
            "\n",
            "Hmm, this sounds like a rate problem. Rate is typically defined as \"distance over time,\" which can be written as speed. In this case, the car's speed would be 60 km per hour. \n",
            "\n",
            "Now, if we want to know how far the car goes in 5 hours, we should multiply its speed by the number of hours it's traveling. That makes sense because speed is distance divided by time, so multiplying them together gives us total distance. \n",
            "\n",
            "Let me write that out:\n",
            "\n",
            "Speed = Distance / Time\n",
            "Total Distance = Speed * Time\n",
            "\n",
            "In this case:\n",
            "Speed = 60 km/h (since the car travels 60 km in 1 hour)\n",
            "Time = 5 hours\n",
            "\n",
            "So, Total Distance = 60 km/h * 5 h\n",
            "\n",
            "Calculating that gives us:\n",
            "\n",
            "60 * 5 = 300 km\n",
            "\n",
            "Therefore, the car will travel 300 kilometers in 5 hours.\n",
            "</think>\n",
            "\n",
            "The car will travel **300 kilometers** in 5 hours.  \n",
            "\n",
            "**Step-by-Step Explanation:**  \n",
            "1. **Determine Speed:** The car travels 60 km in 1 hour, so its speed is \\(60 \\, \\text{km/h}\\).  \n",
            "2. **Calculate Total Distance:** Multiply speed by the number of hours (5):  \n",
            "   \\[\n",
            "   \\text{Distance} = 60 \\, \\text{km/h} \\times 5 \\, \\text{h} = 300 \\, \\text{km}.\n",
            "   \\]  \n",
            "3. **Answer:** The car will travel 300 kilometers in 5 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COT example\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant who answers questions based on your knowledge.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the capital of France?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=1.5, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Displaying the generated response\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHXzUha3fAXD",
        "outputId": "3597f64c-1868-4b76-b3f5-1c2342cdc370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "You are a helpful assistant who answers questions based on your knowledge.user\n",
            "\n",
            "What is the capital of France?assistant\n",
            "\n",
            "The capital of France is Paris. Paris is located in the north-central part of the country and is known for its iconic landmarks such as the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and many more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## COT example\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant that classifies animals as either mammals or non-mammals based on the examples you are given.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Classify the following animals as mammals or non-mammals. Here are a few examples:\\n1. Dog -> Mammal\\n2. Whale -> Mammal\\n3. Lizard -> Non-mammal\\nNow, classify the following:\\n4. Elephant?\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=1.5, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Displaying the generated response\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx5oERDPfjKJ",
        "outputId": "1f779026-eb7f-4658-8b3d-5d77db49cf4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "You are a helpful assistant that classifies animals as either mammals or non-mammals based on the examples you are given.user\n",
            "\n",
            "Classify the following animals as mammals or non-mammals. Here are a few examples:\n",
            "1. Dog -> Mammal\n",
            "2. Whale -> Mammal\n",
            "3. Lizard -> Non-mammal\n",
            "Now, classify the following:\n",
            "4. Elephant?assistant\n",
            "\n",
            "Elephant -> Mammal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Zero Shot example\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a movie writer, very creative and bold, writing abt history and war\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.1, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Displaying the generated response\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "id": "9FcTBIQCgUpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0591f2b1-ebb7-4b70-9888-412678b1198c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "You are a movie writer, very creative and bold, writing abt history and waruser\n",
            "\n",
            "assistant\n",
            "\n",
            "Title: \"Echoes of Valor\"\n",
            "\n",
            "Genre: Historical War Drama\n",
            "\n",
            "Plot:\n",
            "In the heart of World War II, amidst the chaos and destruction of Europe, a young American soldier named Jack Donovan finds himself in the midst of a fierce battle. As he fights for his life, he discovers an ancient artifact hidden beneath the rubble - a mysterious amulet that seems to possess supernatural powers.\n",
            "\n",
            "Jack's unit is ordered to retreat from the battlefield, but as they make their way back to safety, strange things begin to happen. The soldiers start experiencing vivid flashbacks of past battles, and some even claim to see ghosts. Jack realizes that the amulet has given them a glimpse into the future, revealing the horrors that await them if they don't find a way to stop it.\n",
            "\n",
            "As they race against time, Jack and his fellow soldiers uncover a secret society that has been manipulating events on the battlefield for centuries. They soon learn that the amulet holds the key to stopping this group, but at a great cost. Each member of the team must confront their own demons and face their deepest fears in order to save not only themselves, but the entire world from the impending doom.\n",
            "\n",
            "With the help of a brilliant historian named Dr. Eleanor Blackwood, who has her own connection to the amulet, Jack and his team embark on a dangerous mission across Europe, following clues left behind by the society. Along the way, they encounter resistance fighters, Nazi war criminals, and even the ghostly remnants of those who have fought before them.\n",
            "\n",
            "As the stakes grow higher, so does the tension between Jack and Eleanor. Their growing attraction complicates matters further, as they must put aside their personal feelings to focus on the task at hand. But when Jack discovers that Eleanor may be part of the secret society, he must decide whether to trust her or fight her.\n",
            "\n",
            "In a thrilling climax, Jack and his team finally confront the leaders of the secret society in a final battle that will determine the fate of humanity. With the power of the amulet waning, Jack must use all his courage and determination to protect his friends and save the world from the clutches of darkness.\n",
            "\n",
            "\"Echoes of Valor\" is a gripping tale of friendship, love, and sacrifice set against the backdrop of one of the most devastating conflicts in human history. It explores themes of bravery, redemption, and the indomitable human spirit, reminding us that even in the darkest of times, hope can still prevail.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Zero Shot example\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a movie writer, very creative and bold, writing abt history and war\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.1, repetition_penalty=1.1, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Displaying the generated response\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "id": "BwmjqvHHpVL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Zero Shot Prompting\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful movie writer, very creative and bold, writing about history and war.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Write a plot summary for a historical war movie set during the fall of the Roman Empire.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(input_ids, max_new_tokens=2500, temperature=0.1, repetition_penalty=0.5, do_sample=True, eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "# Displaying the generated response\n",
        "response = tokenizer.decode(generated_ids[0], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EgcTSjSq5V5",
        "outputId": "01313f3f-1fd5-49c0-fee7-c4ce7ff0613a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "You are a helpful movie writer, very creative and bold, writing about history and war.user\n",
            "\n",
            "Write a plot summary for a historical war movie set during the fall of the Roman Empire.assistant\n",
            "\n",
            "Title of the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie, set during the fall of the Roman Empire, the movie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Zero Shot Prompting\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful movie writer, very creative and bold, writing about history and war.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Write a plot summary for a historical war movie set during the fall of the Roman Empire.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Example Code to Process the Messages (assuming you're using a specific model setup)\n",
        "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors='pt').to(\"cuda\")\n",
        "generated_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_new_tokens=200,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.2,\n",
        "    no_repeat_ngram_size=3,\n",
        "    num_return_sequences=2,\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    return_dict_in_generate=True,\n",
        "    output_scores=True\n",
        ")\n",
        "\n",
        "\n",
        "# Displaying the generated response\n",
        "# Decoding the multiple generated sequences\n",
        "responses = [\n",
        "    tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_space=True)\n",
        "    for g in generated_ids.sequences\n",
        "]\n",
        "\n",
        "# Displaying the responses\n",
        "for idx, response in enumerate(responses):\n",
        "    print(f\"Response {idx + 1}: {response}\")\n",
        "    print()\n",
        "\n",
        "# print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKoQb5c8rCkY",
        "outputId": "350ba334-2b65-4ee2-8a7a-8bc930e8ebfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response 1: system\n",
            "\n",
            "You are a helpful movie writer, very creative and bold, writing about history and war.user\n",
            "\n",
            "Write a plot summary for a historical war movie set during the fall of the Roman Empire.assistant\n",
            "\n",
            "Title: \"The Last Legion\"\n",
            "\n",
            "In a time when Rome stands on the brink of collapse, young Lucius (Aaron Eckhart) is thrust into power as Emperor. He must navigate through treacherous political waters while battling an invading Germanic army led by General Macrinus (Ben Kingsley). \n",
            "\n",
            "As chaos ensues in Rome, Lucius discovers that his mother has been plotting with King Constantine (Tom Hardy), leader of the last remnants of the once-great Roman legions, to restore their true emperor, Aurelian (Colin Firth).\n",
            "\n",
            "Lucius finds himself caught between loyalty to Rome's crumbling structure and allegiance to those who truly served it - its people. As he embarks on a quest across Europe seeking out allies and resources against the encroaching hordes, he encounters various characters from diverse backgrounds.\n",
            "\n",
            "Throughout this epic journey, Lucious learns more about his family legacy and the importance of preserving ancient traditions amidst modern warfare. Along the way, he also uncovers\n",
            "\n",
            "Response 2: system\n",
            "\n",
            "You are a helpful movie writer, very creative and bold, writing about history and war.user\n",
            "\n",
            "Write a plot summary for a historical war movie set during the fall of the Roman Empire.assistant\n",
            "\n",
            "Title: \"The Last Emperor's Legacy\"\n",
            "\n",
            "In the heart of the crumbling Roman Empire, as its mighty legions begin to falter under the relentless waves of barbarian invasions, young Marcus Aurelius stands at the precipice of an uncertain future.\n",
            "\n",
            "Marcus is a seasoned soldier with his sights firmly fixed on glory in the battlefield. But as Rome crumbles around him, he discovers that true strength lies not just in conquest but also in leadership, empathy, and wisdom. \n",
            "\n",
            "His journey takes him from commanding armies in battlefields across Europe, through treacherous negotiations with Germanic tribes seeking allies or enemies, all while keeping the fragile peace between the warring factions within the empire itself.\n",
            "\n",
            "Alongside this epic struggle against external threats comes internal strife; dissent among the Senate, political maneuvering by ambitious officials vying for power, and personal loss when key figures are betrayed or killed.\n",
            "\n",
            "As tensions mount, Marcus must decide whether to cling onto the fading glories of ancient Rome or forge ahead into\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sDfuuEdMr7IP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}